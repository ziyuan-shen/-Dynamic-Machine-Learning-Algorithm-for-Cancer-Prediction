{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "print(digits.data[0].reshape((8, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1797\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of samples.\n",
    "samples_count = len(digits.images)\n",
    "\n",
    "print(\"Number of samples: \" + str(samples_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training records: 1257\n",
      "Number of testing records : 360\n",
      "Number of scoring records : 180\n"
     ]
    }
   ],
   "source": [
    "# Split the data into data sets and display the number of records for each data set.\n",
    "train_data = digits.data[: int(0.7*samples_count)]\n",
    "train_labels = digits.target[: int(0.7*samples_count)]\n",
    "\n",
    "test_data = digits.data[int(0.7*samples_count): int(0.9*samples_count)]\n",
    "test_labels = digits.target[int(0.7*samples_count): int(0.9*samples_count)]\n",
    "\n",
    "score_data = digits.data[int(0.9*samples_count): ]\n",
    "\n",
    "print(\"Number of training records: \" + str(len(train_data)))\n",
    "print(\"Number of testing records : \" + str(len(test_data)))\n",
    "print(\"Number of scoring records : \" + str(len(score_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        37\n",
      "           1       0.97      0.97      0.97        34\n",
      "           2       1.00      0.97      0.99        36\n",
      "           3       1.00      0.94      0.97        35\n",
      "           4       0.78      0.97      0.87        37\n",
      "           5       0.97      0.97      0.97        38\n",
      "           6       0.97      0.86      0.91        36\n",
      "           7       0.92      0.97      0.94        35\n",
      "           8       0.91      0.89      0.90        35\n",
      "           9       0.97      0.92      0.94        37\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       360\n",
      "   macro avg       0.95      0.94      0.95       360\n",
      "weighted avg       0.95      0.94      0.95       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import scikit-learn packages\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm, metrics\n",
    "scaler = preprocessing.StandardScaler()\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "pipeline = Pipeline([('scaler', scaler), ('svc', clf)])\n",
    "model = pipeline.fit(train_data, train_labels)\n",
    "# Evaluate your model.\n",
    "predicted = model.predict(test_data)\n",
    "\n",
    "print(\"Evaluation report: \\n\\n%s\" % metrics.classification_report(test_labels, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
